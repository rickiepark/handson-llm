{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ETtu9CvVMDR"
   },
   "source": [
    "<h1>10ì¥ í…ìŠ¤íŠ¸ ì„ë² ë”© ëª¨ë¸ ë§Œë“¤ê¸°</h1>\n",
    "<i>ì„ë² ë”© ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ë¯¸ì„¸ íŠœë‹í•˜ëŠ” ë°©ë²• ì‚´í´ ë³´ê¸°</i>\n",
    "\n",
    "<a href=\"https://github.com/rickiepark/handson-llm\"><img src=\"https://img.shields.io/badge/GitHub%20Repository-black?logo=github\"></a>\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rickiepark/handson-llm/blob/main/chapter10.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ <[í•¸ì¦ˆì˜¨ LLM](https://tensorflow.blog/handson-llm/)> ì±… 10ì¥ì˜ ì½”ë“œë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "<a href=\"https://tensorflow.blog/handson-llm/\">\n",
    "<img src=\"https://tensorflow.blog/wp-content/uploads/2025/05/ed95b8eca688ec98a8_llm.jpg\" width=\"350\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uAQmA14B98S"
   },
   "source": [
    "### [ì„ íƒì‚¬í•­] - <img src=\"https://colab.google/static/images/icons/colab.png\" width=100>ì—ì„œ íŒ¨í‚¤ì§€ ì„ íƒí•˜ê¸°\n",
    "\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì„ êµ¬ê¸€ ì½”ë©ì—ì„œ ì‹¤í–‰í•œë‹¤ë©´ ë‹¤ìŒ ì½”ë“œ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ì´ ë…¸íŠ¸ë¶ì—ì„œ í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼  ì„¤ì¹˜í•˜ì„¸ìš”.\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ’¡ **NOTE**: ì´ ë…¸íŠ¸ë¶ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë ¤ë©´ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. êµ¬ê¸€ ì½”ë©ì—ì„œëŠ” **ëŸ°íƒ€ì„ > ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ > í•˜ë“œì›¨ì–´ ê°€ì†ê¸° > T4 GPU**ë¥¼ ì„ íƒí•˜ì„¸ìš”.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0SKNl7ysEl80"
   },
   "outputs": [],
   "source": [
    "# ê¹ƒí—ˆë¸Œì—ì„œ ìœ„ì ¯ ìƒíƒœ ì˜¤ë¥˜ë¥¼ í”¼í•˜ê¸° ìœ„í•´ ì§„í–‰ í‘œì‹œì¤„ì„ ë‚˜íƒ€ë‚´ì§€ ì•Šë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "import os\n",
    "import tqdm\n",
    "from transformers.utils import logging\n",
    "\n",
    "# tqdm ë¹„í™œì„±í™”\n",
    "os.environ[\"DISABLE_TQDM\"] = \"1\"\n",
    "\n",
    "logging.disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D2kxxOfkB98S"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets mteb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UrKluX5YNmu"
   },
   "source": [
    "## ì„ë² ë”© ëª¨ë¸ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywsyZzm5VSER"
   },
   "source": [
    "### ë°ì´í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "9493eb0631904d4d919c167497be9a22",
      "c4ba1e8d65a6433ba5d745b17c7c8c00",
      "b5527633f83e4ddb9d8053a53c063ba7",
      "923d32fb325c49c6916899de34451a76",
      "887c1daae0ed4231b66ab1fa4f773642",
      "5a0ecc61ee6e4e018cb7e1d5737dbbd2",
      "594e2ac63c764942ad75416d0b24be0a",
      "360a1b3634904f7589b01db09b4a474c",
      "f46dabaa67754c06b8062ec542998c4f",
      "651b137b182d4ba4b953e16b7ed3acd9",
      "21696e5dfe1d4154bedb9c1459e7b3ab",
      "e6847a2e803b4870a49519212e05b825",
      "fac54c34c6cc4b7d8cf839e2817f3903",
      "b5f2169d00084970a5cbaef1b31dac0b",
      "6f2d335122174b68a5599d21682c5cbb",
      "4044338572c6424c8a45e6c169c255e4",
      "ceb21f3718a34969978795c567fea3aa",
      "461bd3d6611a4664a2a69f7811d7507f",
      "83e8e66439d44baaa83bf1efa10c9b39",
      "cbfe30bca79346bf9c7b17367e1f22a3",
      "b71026e134d04d86a3493bee4e306f3f",
      "141b53baf62e48128f8749b5f88b9137",
      "7c9f8835d3e94acc940dd42b7a43ede7",
      "62d3440daa9b450ca578504dfd3ac580",
      "4f07d4693bb34dc38645938b30adcd2b",
      "303448a9e8b14e4da669ebb03f83fa17",
      "3be096b8661641ec9536986b59785b51",
      "8efe7eae2eac48ee82e40dd1958a0753",
      "9c0284c572c64570836d3b87eca7a8d1",
      "799a2b0cfd5a44bcb075d26c3e0c838d",
      "0c106617cc10416cb8bc49db7980c590",
      "05622f2b7b16461b844502843f5c6b61",
      "ed5de2b963574797b73bbf995cfd0b30",
      "078bac8b7c484fadb27c40e44689b463",
      "1861f966cfcf40549012155ca82651b5",
      "f928e913210e488191d27e24f9f45d98",
      "a9a810bfe30e4ab9b9d43e50182cc7f2",
      "e798994f3203475ca02c61b95f1b9617",
      "59ffb1b912b9423d9710a2241f1e73f2",
      "ac674b307d2b4818b11e133375b5177d",
      "7b368a6ef99c4a7489ab3cc36c2d8129",
      "346912f7d77c4424aa4b4faaeb32e74e",
      "2c2db4ac4fd9427cb030f2bd5f6bc4fc",
      "9bfec1bd93f9489bbf3ace25a24c01de",
      "5100959cbc9649b2af7bea3c007ab6b6",
      "5c5e61dfe6bc4a6d8879f02651ac44b8",
      "ba4a18f751ba47d9b96595dab38b0d0d",
      "699e050bb8684970a296f675d6314ae9",
      "75e86a50c79a4e82a2e1b3fa38abf123",
      "285e777a02584083a3b83c3303f54e67",
      "cc4349834ffa49d2b4bed8ad3868f8ca",
      "39c4faaa790d48d89c38e01c32cc76fb",
      "ffe3a14c673d4f6c8a243002b56b3bad",
      "b99997c685ce4afaae4b796b7092d22a",
      "975061b83cac43e09619a88b0e9c5e1e"
     ]
    },
    "id": "Ahk0SJDKVy6F",
    "outputId": "58867852-3c96-4f1d-e23d-cd366ef5e2ca"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9493eb0631904d4d919c167497be9a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6847a2e803b4870a49519212e05b825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9f8835d3e94acc940dd42b7a43ede7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078bac8b7c484fadb27c40e44689b463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_matched split:   0%|          | 0/9796 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5100959cbc9649b2af7bea3c007ab6b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_mismatched split:   0%|          | 0/9847 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# GLUEì—ì„œ MNLI ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "# 0 = ìˆ˜ë°˜, 1 = ì¤‘ë¦½, 2 = ëª¨ìˆœ\n",
    "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "train_dataset = train_dataset.remove_columns(\"idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-BHO4-qwMDO",
    "outputId": "88cad45a-11e8-4268-a2a7-51998a80f5fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'One of our number will carry out your instructions minutely.',\n",
       " 'hypothesis': 'A member of my team will execute your orders with immense precision.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wO23cXLXeFU"
   },
   "source": [
    "### ëª¨ë¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C4qLaPR6nrqC",
    "outputId": "a127f542-f0fc-4e5e-be4a-e1660e95d878"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-uncased. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# BERT ë² ì´ìŠ¤ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "embedding_model = SentenceTransformer('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAiL21AuYKVI"
   },
   "source": [
    "### ì†ì‹¤ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OgmtKckBXiK9"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ì†Œí”„íŠ¸ë§¥ìŠ¤ ì†ì‹¤ì„ ìœ„í•´ ëª…ì‹œì ìœ¼ë¡œ ë ˆì´ë¸”ì˜ ê°œìˆ˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "train_loss = losses.SoftmaxLoss(\n",
    "    model=embedding_model,\n",
    "    sentence_embedding_dimension=embedding_model.get_sentence_embedding_dimension(),\n",
    "    num_labels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tH0efspwlOX2"
   },
   "source": [
    "### í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "d56cd8d8bc434ada93b9d5ea91548c76",
      "2fdbfb9dcd3942f6aafe14290d172c50",
      "abef5cf2fb604918ba67afa1d1bbc641",
      "c23e2188f3614f94a46e260b61a1d624",
      "40b17fc7bd0944b78398ff5c6d36a6e9",
      "8fae500398104bbcad7a66701b68fba2",
      "2a46a617da314ccfb54662135bf989a6",
      "ab8fdadd9ca543d48066c27a235cf5c2",
      "a5ddacca5f2e4cafb4001388d3868a1d",
      "14085a5743f04f8090d1a237035bb2b8",
      "b1cf48d72b4f4c0eb7fdd2923203f0f1",
      "cb819d93fcc842fca57fd65f18fe1e6b",
      "d748901fda88437a9183e39fe003f56a",
      "36fbb78d86224904822c4ba8ba28adb3",
      "6d5f7770377040e5a80df24e0a923b29",
      "77f32bc7613f4aa1a8a3757a90484dc1",
      "b8643a904c554be4a797a76678db8973",
      "1ee3a42891ff4c99a09424ace244e16c",
      "3b047b5b0cdf4f67b70bbac679f52530",
      "178449a334e645a1a71b456bb72683fe",
      "a1176d08963c46b08d20bd7c5afc90e4",
      "eca71989e08746749b22c6b93ef2666c",
      "78570ff0b72b48ac93e96dd70aad84bb",
      "986ab7a43d7544cc9070cd1090b2add2",
      "aa8bbf883a944c24a3b136efc95bcc3a",
      "604bde7aad2347b288212683c0c8ef60",
      "56e225ea494a462b844ad4f939b5d8b2",
      "f2f8b275d0b14a3cb4818ed9d2519e67",
      "3c0bbb43362342d5ae4bfbeff451ac0e",
      "c15f5a871ddb424285619cdfc09e8a95",
      "a4b548e251874068a9ce5b682eafd7c7",
      "193ecd09ec394397af478d015b263b5e",
      "cf5d2cbbc9b24c6fb53ea6b72df88c42"
     ]
    },
    "id": "f8ZsoY0AretV",
    "outputId": "74cc9c72-e475-4a3c-a174-6c47596af394"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56cd8d8bc434ada93b9d5ea91548c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb819d93fcc842fca57fd65f18fe1e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78570ff0b72b48ac93e96dd70aad84bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "# STSBë¥¼ ìœ„í•´ ì„ë² ë”© ìœ ì‚¬ë„ í‰ê°€ìë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\",\n",
    "    similarity_fn_names=[\"cosine\", \"euclidean\", \"manhattan\", \"dot\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umikSmoYIP07"
   },
   "source": [
    "### í›ˆë ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8uAAhNs0ocoV"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "# í›ˆë ¨ ë§¤ê°œë³€ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"base_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    report_to=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591,
     "referenced_widgets": [
      "0fbae6ac4deb4d02b445aa18a48015ab",
      "a69fe990a65044dcb2e38ad30b96846d",
      "341aca618092402a979e915be7677a17",
      "f91919d8a46347a3bbe1bb409a9942a1",
      "0c9c9c882cd7444d8fdf03c09c34f704",
      "00e59ac15dd74159866f4d23ca8ee4b9",
      "0af88b2364db4ada84c0eacb71cbf4a7",
      "67762e2e45d74367ac07515ddb1ccb70",
      "35b211f7f85141f792408be9195c043c",
      "1b6c168a02304b33af8ef8c8273d5f6a",
      "c826ca6ef97341a0a9ca28ff4b793888"
     ]
    },
    "id": "JKA_L39FpAoM",
    "outputId": "1f79dba0-0d05-4922-e6f6-c0e2a366861f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbae6ac4deb4d02b445aa18a48015ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sentence_transformers.data_collator:Column 'hypothesis' is at index 1, whereas a column with this name is usually expected at index 0. Note that the column order can be important for some losses, e.g. MultipleNegativesRankingLoss will always consider the first column as the anchor and the second as the positive, regardless of the dataset column names. Consider renaming the columns to match the expected order, e.g.:\n",
      "dataset = dataset.select_columns(['hypothesis', 'entailment', 'contradiction'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1501' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1501/1563 05:30 < 00:13, 4.54 it/s, Epoch 0.96/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.067400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.890700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.846300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.832100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.838300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.816800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.799000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.775700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.773500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.757800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.736400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.750100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.724800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NA16lEaseOq"
   },
   "outputs": [],
   "source": [
    "# í›ˆë ¨ëœ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9xjkvCWwrp_"
   },
   "source": [
    "### MTEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Hueu4upxVYb"
   },
   "outputs": [],
   "source": [
    "from mteb import MTEB\n",
    "\n",
    "# í‰ê°€ ì‘ì—…ì„ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "evaluation = MTEB(tasks=[\"Banking77Classification\"])\n",
    "\n",
    "# ê²°ê³¼ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "results = evaluation.run(embedding_model)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56V2ma89uJwN"
   },
   "source": [
    "âš ï¸ **VRAM ë¹„ìš°ê¸°** - ë‹¤ìŒ ì½”ë“œë¥¼ ì‚¬ìš©í•´ VRAM(GPU RAM)ì„ ë¹„ìš°ì„¸ìš”. ë§Œì•½ ë¹„ì›Œì§€ì§€ ì•Šìœ¼ë©´ ë…¸íŠ¸ë¶ì„ ì¬ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤. ì½”ë©ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì˜¤ë¥¸ìª½ì˜ ë¦¬ì†ŒìŠ¤ íƒ­ì—ì„œ VRAMì´ ì¤„ì–´ ë“¤ì—ˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜ëŠ” `!nvidia-smi` ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ í˜„ì¬ ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6d0GcY8cnNs4"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYnRRSDN06eB"
   },
   "source": [
    "### ì†ì‹¤ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tq8Yb6IB2LFI"
   },
   "source": [
    "#### ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì†ì‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qEmnjQQPuszQ"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "# GLUEë¡œë¶€í„° MNLI ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "# 0 = ìˆ˜ë°˜, 1 = ì¤‘ë¦½, 2 = ëª¨ìˆœ\n",
    "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "train_dataset = train_dataset.remove_columns(\"idx\")\n",
    "\n",
    "# (ì¤‘ë¦½/ëª¨ìˆœ)=0, (ìˆ˜ë°˜)=1\n",
    "mapping = {2: 0, 1: 0, 0:1}\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": train_dataset[\"premise\"],\n",
    "    \"sentence2\": train_dataset[\"hypothesis\"],\n",
    "    \"label\": [float(mapping[label]) for label in train_dataset[\"label\"]]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "np5bMwgO5y8g"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "# STSBë¥¼ ìœ„í•œ ì„ë² ë”© ìœ ì‚¬ë„ í‰ê°€ìë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\",\n",
    "    similarity_fn_names=[\"cosine\", \"euclidean\", \"manhattan\", \"dot\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ikky866vdseY"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import losses, SentenceTransformer\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "# ëª¨ë¸\n",
    "embedding_model = SentenceTransformer('bert-base-uncased')\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜\n",
    "train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n",
    "\n",
    "# í›ˆë ¨ ë§¤ê°œë³€ìˆ˜\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"cosineloss_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í›ˆë ¨\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E69gBMG46WVF"
   },
   "outputs": [],
   "source": [
    "# í›ˆë ¨ëœ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnGpHqy46YS3"
   },
   "source": [
    "âš ï¸ **VRAM ë¹„ìš°ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xvps7UpznPD4"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yh0toLx2Ni7"
   },
   "source": [
    "#### MNR ì†ì‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzToWFH0vZzz"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "# GLUEì—ì„œ MNLI ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "mnli = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "mnli = mnli.remove_columns(\"idx\")\n",
    "mnli = mnli.filter(lambda x: True if x['label'] == 0 else False)\n",
    "\n",
    "# ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "train_dataset = {\"anchor\": [], \"positive\": [], \"negative\": []}\n",
    "soft_negatives = mnli[\"hypothesis\"]\n",
    "random.shuffle(soft_negatives)\n",
    "for row, soft_negative in tqdm(zip(mnli, soft_negatives)):\n",
    "    train_dataset[\"anchor\"].append(row[\"premise\"])\n",
    "    train_dataset[\"positive\"].append(row[\"hypothesis\"])\n",
    "    train_dataset[\"negative\"].append(soft_negative)\n",
    "train_dataset = Dataset.from_dict(train_dataset)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wP_s1yAB7D7I"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "# STSBë¥¼ ìœ„í•´ ì„ë² ë”© ìœ ì‚¬ë„ í‰ê°€ìë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\",\n",
    "    similarity_fn_names=[\"cosine\", \"euclidean\", \"manhattan\", \"dot\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-Q2m0yzkRvW"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import losses, SentenceTransformer\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "# ëª¨ë¸\n",
    "embedding_model = SentenceTransformer('bert-base-uncased')\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=embedding_model)\n",
    "\n",
    "# í›ˆë ¨ ë§¤ê°œë³€ìˆ˜\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"mnrloss_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í›ˆë ¨\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvPEvgf98uS8"
   },
   "outputs": [],
   "source": [
    "# í›ˆë ¨ëœ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND1ej1ag054E"
   },
   "source": [
    "## ë¯¸ì„¸ íŠœë‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqATI-1V7coM"
   },
   "source": [
    "âš ï¸ **VRAM ë¹„ìš°ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkWj0SfYnRFd"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGxyXucEkjfw"
   },
   "source": [
    "### ì§€ë„ í•™ìŠµ ë°©ë²•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GXBTm_C-IPE"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "# GLUEì—ì„œ MNLI ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "# 0 = ìˆ˜ë°˜, 1 = ì¤‘ë¦½, 2 = ëª¨ìˆœ\n",
    "train_dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(50_000))\n",
    "train_dataset = train_dataset.remove_columns(\"idx\")\n",
    "\n",
    "# STSBë¥¼ ìœ„í•´ ì„ë² ë”© ìœ ì‚¬ë„ í‰ê°€ìë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\",\n",
    "    similarity_fn_names=[\"cosine\", \"euclidean\", \"manhattan\", \"dot\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQ3vW2VTA9dN"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import losses, SentenceTransformer\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "# ëª¨ë¸\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=embedding_model)\n",
    "\n",
    "# í›ˆë ¨ ë§¤ê°œë³€ìˆ˜\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"finetuned_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í›ˆë ¨\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaPJIpkS-ZrT"
   },
   "outputs": [],
   "source": [
    "# í›ˆë ¨ëœ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pHpVCwmk-XW"
   },
   "outputs": [],
   "source": [
    "# ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "original_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "evaluator(original_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ii6sIMpH7d7S"
   },
   "source": [
    "âš ï¸ **VRAM ë¹„ìš°ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGCTfC-unSL1"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvCPXCSZkkxm"
   },
   "source": [
    "### ì¦ì‹ SBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtoEArJElrZh"
   },
   "source": [
    "**ë‹¨ê³„ 1:** í¬ë¡œìŠ¤ ì¸ì½”ë”ë¥¼ ë¯¸ì„¸ íŠœë‹í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJhEDAeeyhPD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, Dataset\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers.datasets import NoDuplicatesDataLoader\n",
    "\n",
    "# í¬ë¡œìŠ¤ ì¸ì½”ë”ë¥¼ ìœ„í•´ 10,000ê°œì˜ ë¬¸ì„œë¡œ êµ¬ì„±ëœ ë°ì´í„°ì…‹ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "dataset = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(10_000))\n",
    "mapping = {2: 0, 1: 0, 0:1}\n",
    "\n",
    "# ë°ì´í„° ë¡œë”\n",
    "gold_examples = [\n",
    "    InputExample(texts=[row[\"premise\"], row[\"hypothesis\"]], label=mapping[row[\"label\"]])\n",
    "    for row in tqdm(dataset)\n",
    "]\n",
    "gold_dataloader = NoDuplicatesDataLoader(gold_examples, batch_size=32)\n",
    "\n",
    "# ë°ì´í„° ì²˜ë¦¬ë¥¼ ì‰½ê²Œ í•˜ê¸° ìœ„í•´ íŒë‹¤ìŠ¤ ë°ì´í„°í”„ë ˆì„ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "gold = pd.DataFrame(\n",
    "    {\n",
    "    'sentence1': dataset['premise'],\n",
    "    'sentence2': dataset['hypothesis'],\n",
    "    'label': [mapping[label] for label in dataset['label']]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_MHAJzl2H6Z"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "# ê³¨ë“œ ë°ì´í„°ì…‹ì—ì„œ í¬ë¡œìŠ¤ ì¸ì½”ë”ë¥¼ í›ˆë ¨í•©ë‹ˆë‹¤.\n",
    "cross_encoder = CrossEncoder('bert-base-uncased', num_labels=2)\n",
    "cross_encoder.fit(\n",
    "    train_dataloader=gold_dataloader,\n",
    "    epochs=1,\n",
    "    show_progress_bar=True,\n",
    "    warmup_steps=100,\n",
    "    use_amp=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0OcVG6WmMOJ"
   },
   "source": [
    "**ë‹¨ê³„ 2:** ìƒˆë¡œìš´ ë¬¸ì¥ ìŒì„ ë§Œë“­ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgx8N8a8kVrZ"
   },
   "outputs": [],
   "source": [
    "# í¬ë¡œìŠ¤ ì¸ì½”ë”ë¡œ ë ˆì´ë¸”ì„ ì˜ˆì¸¡í•  ì‹¤ë²„ ë°ì´í„°ì…‹ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "silver = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(10_000, 50_000))\n",
    "pairs = list(zip(silver['premise'], silver['hypothesis']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcG7cDG5qrwX"
   },
   "source": [
    "**ë‹¨ê³„ 3:** ë¯¸ì„¸ íŠœë‹ëœ í¬ë¡œìŠ¤ ì¸ì½”ë”ë¡œ ìƒˆë¡œìš´ ë¬¸ì¥ ìŒ(ì‹¤ë²„ ë°ì´í„°ì…‹)ì— ë ˆì´ë¸”ì„ í• ë‹¹í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9Yuhzxq2NMj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ë¯¸ì„¸ íŠœë‹ëœ í¬ë¡œìŠ¤ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•´ ë¬¸ì¥ ìŒì— ë ˆì´ë¸”ì„ í• ë‹¹í•©ë‹ˆë‹¤.\n",
    "output = cross_encoder.predict(pairs, apply_softmax=True,\n",
    "                               show_progress_bar=True)\n",
    "silver = pd.DataFrame(\n",
    "    {\n",
    "        \"sentence1\": silver[\"premise\"],\n",
    "        \"sentence2\": silver[\"hypothesis\"],\n",
    "        \"label\": np.argmax(output, axis=1)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9Jd-Kssqzk_"
   },
   "source": [
    "**ë‹¨ê³„ 4:** í™•ì¥ëœ ë°ì´í„°ì…‹(ê³¨ë“œ ë°ì´í„°ì…‹ + ì‹¤ë²„ ë°ì´í„°ì…‹)ìœ¼ë¡œ ë°”ì´ ì¸ì½”ë”(SBERT)ë¥¼ í›ˆë ¨í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fp09qxMhzagi"
   },
   "outputs": [],
   "source": [
    "# ê³¨ë“œ ë°ì´í„°ì…‹ê³¼ ì‹¤ë²„ ë°ì´í„°ì…‹ì„ í•©ì¹©ë‹ˆë‹¤.\n",
    "data = pd.concat([gold, silver], ignore_index=True, axis=0)\n",
    "data = data.drop_duplicates(subset=['sentence1', 'sentence2'], keep=\"first\")\n",
    "train_dataset = Dataset.from_pandas(data, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-6RW_wOAOwO"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "# STSBë¥¼ ìœ„í•œ ì„ë² ë”© ìœ ì‚¬ë„ í‰ê°€ìë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\",\n",
    "    similarity_fn_names=[\"cosine\", \"euclidean\", \"manhattan\", \"dot\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MK1KybOI_uIY"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import losses, SentenceTransformer\n",
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "# ëª¨ë¸\n",
    "embedding_model = SentenceTransformer('bert-base-uncased')\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜\n",
    "train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n",
    "\n",
    "# í›ˆë ¨ ë§¤ê°œë³€ìˆ˜\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"augmented_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í›ˆë ¨\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_NHjK75z58G"
   },
   "outputs": [],
   "source": [
    "# í›ˆë ¨ëœ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwAaFBHvDcFi"
   },
   "outputs": [],
   "source": [
    "trainer.accelerator.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CX6lArIH0h1A"
   },
   "source": [
    "**ë‹¨ê³„ 5**: ì‹¤ë²„ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyPBGfxp0D_7"
   },
   "outputs": [],
   "source": [
    "# ê³¨ë“œ ë°ì´í„°ì…‹ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "data = pd.concat([gold], ignore_index=True, axis=0)\n",
    "data = data.drop_duplicates(subset=['sentence1', 'sentence2'], keep=\"first\")\n",
    "train_dataset = Dataset.from_pandas(data, preserve_index=False)\n",
    "\n",
    "# ëª¨ë¸\n",
    "embedding_model = SentenceTransformer('bert-base-uncased')\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜\n",
    "train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n",
    "\n",
    "# í›ˆë ¨ ë§¤ê°œë³€ìˆ˜\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"gold_only_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í›ˆë ¨\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6L8_5TLJ0jdK"
   },
   "outputs": [],
   "source": [
    "# í›ˆë ¨ëœ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZujSUsu0sHU"
   },
   "source": [
    "ì‹¤ë²„ ë°ì´í„°ì…‹ê³¼ ê³¨ë“œ ë°ì´í„°ì…‹ì„ ëª¨ë‘ ì‚¬ìš©í–ˆì„ ë•Œì™€ ë¹„êµí•˜ë©´ ê³¨ë“œ ë°ì´í„°ì…‹ë§Œ ì‚¬ìš©í•œ ê²½ìš° ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ê°ì†Œí•©ë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVq3FSZL7gK7"
   },
   "source": [
    "âš ï¸ **VRAM ë¹„ìš°ê¸°**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gckDRJ1nUfo"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7RNAKVl3wmM"
   },
   "source": [
    "## ë¹„ì§€ë„ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq_phjTb31gX"
   },
   "source": [
    "### TSDAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8yMdUf_WwErS"
   },
   "outputs": [],
   "source": [
    "# ì¶”ê°€ì ì¸ í† í¬ë‚˜ì´ì €ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ruI-lOZYZt7J"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import Dataset, load_dataset\n",
    "from sentence_transformers.datasets import DenoisingAutoEncoderDataset\n",
    "\n",
    "# ì „ì œì™€ ê°€ì„¤ì„ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "mnli = load_dataset(\"glue\", \"mnli\", split=\"train\").select(range(25_000))\n",
    "flat_sentences = mnli[\"premise\"] + mnli[\"hypothesis\"]\n",
    "\n",
    "# ì…ë ¥ ë°ì´í„°ì— ì¡ìŒì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "damaged_data = DenoisingAutoEncoderDataset(list(set(flat_sentences)))\n",
    "\n",
    "# ë°ì´í„°ì…‹ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "train_dataset = {\"damaged_sentence\": [], \"original_sentence\": []}\n",
    "for data in tqdm(damaged_data):\n",
    "    train_dataset[\"damaged_sentence\"].append(data.texts[0])\n",
    "    train_dataset[\"original_sentence\"].append(data.texts[1])\n",
    "train_dataset = Dataset.from_dict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mymxiQ9A1eQm"
   },
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tl6CzdwNA1tC"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "# STSBë¥¼ ìœ„í•œ ì„ë² ë”© ìœ ì‚¬ë„ í‰ê°€ìë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "val_sts = load_dataset('glue', 'stsb', split='validation')\n",
    "evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_sts[\"sentence1\"],\n",
    "    sentences2=val_sts[\"sentence2\"],\n",
    "    scores=[score/5 for score in val_sts[\"label\"]],\n",
    "    main_similarity=\"cosine\",\n",
    "    similarity_fn_names=[\"cosine\", \"euclidean\", \"manhattan\", \"dot\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pYM298tWlacT"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import models, SentenceTransformer\n",
    "\n",
    "# ì„ë² ë”© ëª¨ë¸ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "word_embedding_model = models.Transformer('bert-base-uncased')\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), 'cls')\n",
    "embedding_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5RZ8tQFSlIHm"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "# ì¡ìŒì œê±° ì˜¤í†  ì¸ì½”ë” ì†ì‹¤\n",
    "train_loss = losses.DenoisingAutoEncoderLoss(\n",
    "    embedding_model, tie_encoder_decoder=True\n",
    ")\n",
    "train_loss.decoder = train_loss.decoder.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYApurOS07x0"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
    "from sentence_transformers.training_args import SentenceTransformerTrainingArguments\n",
    "\n",
    "# í›ˆë ¨ ë§¤ê°œë³€ìˆ˜\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"tsdae_embedding_model\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=100,\n",
    "    fp16=True,\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    report_to=[]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ í›ˆë ¨\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=embedding_model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGxh6fTa7qIh"
   },
   "outputs": [],
   "source": [
    "# í›ˆë ¨ëœ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
    "evaluator(embedding_model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
